# Problem Research Prompts: Rubicon

Generated: 2026-02-07
Source: https://www.getrubicon.com/
Format: v5.0 multi-hypothesis (4 unified prompts)

Run each prompt in Claude Deep Research. Save results to `research/` folder.

---

## Prompt 1: Prevalence Research

# Problem Research: Rubicon

## Hypotheses Under Investigation

We've extracted the following problem hypotheses from the Rubicon website (getrubicon.com), an AI-powered due diligence platform for investors and startups:

1. **H1:** Due diligence teams must manually review thousands of unstructured documents under tight deal timelines, making thorough analysis impractical within the time available
2. **H2:** Financial anomalies and risk signals buried in deal documents go undetected during due diligence because reviewers cannot systematically cross-reference information across large document sets
3. **H3:** Finding specific information across thousands of unstructured pages in deal data rooms requires excessive time, leading to incomplete analysis or missed findings
4. **H4:** Due diligence work across analysts, legal teams, and leadership is fragmented, resulting in inconsistent risk assessments and duplicated review effort
5. **H5:** Portfolio managers lack continuous visibility into portfolio company health between formal reporting periods, creating blind spots for emerging risks
6. **H6:** Startups preparing for investor due diligence spend excessive founder time organizing documents and responding to information requests, diverting attention from building the business

These are independent, unranked hypotheses. Your research may validate some, invalidate others, or reveal that some are symptoms of a deeper problem. Report what you find — don't force-fit findings to hypotheses.

---

## Prevalence Research

**Find:**
- What percentage of M&A, PE, and VC deals involve manual document review as the primary due diligence method?
- What percentage of due diligence processes rely on unstructured documents (PDFs, Word docs, spreadsheets) vs. structured data?
- How common is it for due diligence teams to miss findings due to time constraints? What percentage of deals have post-close discoveries?
- How prevalent are financial irregularities or anomalies in deal targets? What percentage of deals surface issues during due diligence vs. after close?
- What percentage of investment firms report fragmented or inconsistent due diligence workflows across their teams?
- How common is the complaint among portfolio managers that they lack real-time visibility between reporting periods?
- What percentage of startup founders report that fundraising preparation (including due diligence) consumes significant time?

**For each hypothesis, determine:**
- Does evidence support or contradict this hypothesis?
- Is this a root problem or a symptom of something deeper?
- What did you find that wasn't anticipated by any hypothesis?

**Sources to prioritize:**
- Industry surveys from Deloitte, PwC, EY, KPMG on due diligence practices
- Professional association reports (CFA Institute, AICPA, ILPA, NVCA)
- Academic studies on M&A due diligence effectiveness
- PE/VC industry benchmarks and annual reports
- Startup founder surveys (First Round Capital, Carta, DocSend)

**Citation format:**
- Claim: [finding]
- Relevant hypothesis: [H1, H2, etc. — or "new finding" if not anticipated]
- Source: [org name]
- Date: [date]
- URL: [url]
- Quote: [verbatim excerpt if available]

**Important:** Flag uncertainty rather than speculate. If evidence is ambiguous, say so. If a hypothesis appears to be a symptom rather than a root cause, explain what the deeper cause might be.

**NOT in scope (belongs to Market workspace):** Total addressable market, number of potential users, dollar impact, industry revenue figures, market growth trends.

---

## Prompt 2: Severity Research

# Problem Research: Rubicon

## Hypotheses Under Investigation

We've extracted the following problem hypotheses from the Rubicon website (getrubicon.com), an AI-powered due diligence platform for investors and startups:

1. **H1:** Due diligence teams must manually review thousands of unstructured documents under tight deal timelines, making thorough analysis impractical within the time available
2. **H2:** Financial anomalies and risk signals buried in deal documents go undetected during due diligence because reviewers cannot systematically cross-reference information across large document sets
3. **H3:** Finding specific information across thousands of unstructured pages in deal data rooms requires excessive time, leading to incomplete analysis or missed findings
4. **H4:** Due diligence work across analysts, legal teams, and leadership is fragmented, resulting in inconsistent risk assessments and duplicated review effort
5. **H5:** Portfolio managers lack continuous visibility into portfolio company health between formal reporting periods, creating blind spots for emerging risks
6. **H6:** Startups preparing for investor due diligence spend excessive founder time organizing documents and responding to information requests, diverting attention from building the business

These are independent, unranked hypotheses. Your research may validate some, invalidate others, or reveal that some are symptoms of a deeper problem. Report what you find — don't force-fit findings to hypotheses.

---

## Severity Research

**Find:**
- How many hours/weeks does a typical due diligence process take? How many person-hours are spent on document review specifically?
- How many documents are typically in a deal data room? What volume of pages must be reviewed?
- What is the typical timeline pressure — how many weeks are teams given vs. how much time the review actually needs?
- How many hours do analysts spend searching for specific information within data rooms? What percentage of review time is search vs. analysis?
- How frequently do missed anomalies or overlooked risks lead to post-acquisition problems? What are the consequences?
- How much time is spent on duplicated effort when multiple teams review the same documents independently?
- How many hours per week do portfolio managers spend compiling information between formal reporting cycles?
- How many hours do startup founders spend preparing for and managing due diligence during a fundraise?

**For each hypothesis, determine:**
- Does evidence support or contradict this hypothesis?
- Is this a root problem or a symptom of something deeper?
- What did you find that wasn't anticipated by any hypothesis?

**Sources to prioritize:**
- Time studies and workflow analyses from consulting firms
- Case studies of due diligence failures and post-close discoveries
- Practitioner surveys on time allocation during deal processes
- Data room provider statistics (Intralinks, Datasite, Firmex) on document volumes
- Academic research on information overload and decision quality under time pressure
- Startup founder time-use studies during fundraising

**Citation format:**
- Claim: [finding]
- Relevant hypothesis: [H1, H2, etc. — or "new finding" if not anticipated]
- Source: [org name]
- Date: [date]
- URL: [url]
- Quote: [verbatim excerpt if available]

**Important:** Focus on time/effort lost, not dollar figures. Flag uncertainty rather than speculate. If evidence is ambiguous, say so. If a hypothesis appears to be a symptom rather than a root cause, explain what the deeper cause might be.

**NOT in scope (belongs to Market workspace):** Total addressable market, number of potential users, dollar impact, industry revenue figures, market growth trends.

---

## Prompt 3: Customer Voice Research

# Problem Research: Rubicon

## Hypotheses Under Investigation

We've extracted the following problem hypotheses from the Rubicon website (getrubicon.com), an AI-powered due diligence platform for investors and startups:

1. **H1:** Due diligence teams must manually review thousands of unstructured documents under tight deal timelines, making thorough analysis impractical within the time available
2. **H2:** Financial anomalies and risk signals buried in deal documents go undetected during due diligence because reviewers cannot systematically cross-reference information across large document sets
3. **H3:** Finding specific information across thousands of unstructured pages in deal data rooms requires excessive time, leading to incomplete analysis or missed findings
4. **H4:** Due diligence work across analysts, legal teams, and leadership is fragmented, resulting in inconsistent risk assessments and duplicated review effort
5. **H5:** Portfolio managers lack continuous visibility into portfolio company health between formal reporting periods, creating blind spots for emerging risks
6. **H6:** Startups preparing for investor due diligence spend excessive founder time organizing documents and responding to information requests, diverting attention from building the business

These are independent, unranked hypotheses. Your research may validate some, invalidate others, or reveal that some are symptoms of a deeper problem. Report what you find — don't force-fit findings to hypotheses.

---

## Customer Voice Research

**Find:**
- Verbatim quotes from due diligence professionals (analysts, associates, VPs) about the pain of manual document review
- Verbatim quotes about missing things during due diligence — fear, frustration, near-misses
- Verbatim quotes about searching for information in data rooms — the experience of looking for a needle in a haystack
- Verbatim quotes about coordination problems across due diligence teams — handoff failures, inconsistencies, wasted effort
- Verbatim quotes from portfolio managers about the gap between reporting periods — what they worry about, what they can't see
- Verbatim quotes from startup founders about the burden of managing due diligence during a fundraise
- Workarounds people describe — spreadsheets, manual trackers, color-coded folders, late nights
- Emotional language — frustration, resignation, anxiety, exhaustion

**For each hypothesis, determine:**
- Does evidence support or contradict this hypothesis?
- Is this a root problem or a symptom of something deeper?
- What did you find that wasn't anticipated by any hypothesis?

**Sources to prioritize:**
- Reddit (r/finance, r/investing, r/privateequity, r/venturecapital, r/startups, r/accounting)
- Wall Street Oasis forums, Blind, Glassdoor
- LinkedIn posts from PE/VC professionals, investment bankers, startup founders
- G2/Capterra reviews of data room and due diligence tools (Intralinks, Datasite, DealRoom, Ansarada)
- Podcasts and interviews with deal professionals
- Blog posts and articles by practitioners describing their workflow
- Quora threads on due diligence experience

**Citation format:**
- Claim: [finding]
- Relevant hypothesis: [H1, H2, etc. — or "general" if it spans multiple]
- Source: [org name]
- Date: [date]
- URL: [url]
- Quote: [verbatim excerpt — exact words, not paraphrased]

**Important:** Capture exact words. Paraphrasing destroys the emotional signal. Tag each quote with which hypothesis it relates to. Look for patterns — if multiple people describe the same frustration independently, that's a strong signal. Flag uncertainty rather than speculate.

**NOT in scope (belongs to Market workspace):** Total addressable market, number of potential users, dollar impact, industry revenue figures, market growth trends.

---

## Prompt 4: Current Solutions Research

# Problem Research: Rubicon

## Hypotheses Under Investigation

We've extracted the following problem hypotheses from the Rubicon website (getrubicon.com), an AI-powered due diligence platform for investors and startups:

1. **H1:** Due diligence teams must manually review thousands of unstructured documents under tight deal timelines, making thorough analysis impractical within the time available
2. **H2:** Financial anomalies and risk signals buried in deal documents go undetected during due diligence because reviewers cannot systematically cross-reference information across large document sets
3. **H3:** Finding specific information across thousands of unstructured pages in deal data rooms requires excessive time, leading to incomplete analysis or missed findings
4. **H4:** Due diligence work across analysts, legal teams, and leadership is fragmented, resulting in inconsistent risk assessments and duplicated review effort
5. **H5:** Portfolio managers lack continuous visibility into portfolio company health between formal reporting periods, creating blind spots for emerging risks
6. **H6:** Startups preparing for investor due diligence spend excessive founder time organizing documents and responding to information requests, diverting attention from building the business

These are independent, unranked hypotheses. Your research may validate some, invalidate others, or reveal that some are symptoms of a deeper problem. Report what you find — don't force-fit findings to hypotheses.

---

## Current Solutions Research

**Find:**
- What tools do due diligence teams currently use for document review? (virtual data rooms, PDF readers, manual checklists, spreadsheets)
- What AI-powered due diligence tools already exist? (e.g., Kira Systems, Luminance, Evisort, DiligenceVault, Daloopa, AlphaSense) What do they do well? Where do they fall short?
- What do virtual data room providers (Intralinks, Datasite, Firmex, Ansarada) offer for search and analysis? Why isn't built-in search sufficient?
- What portfolio monitoring tools exist (Visible, Carta, Chronograph, eFront)? What gaps do portfolio managers report?
- What tools do startups use to manage investor due diligence (DocSend, Notion, Google Drive, dedicated data rooms)? Where do they break down?
- What workarounds do teams use when tools fail? (manual cross-referencing, parallel reviews, hiring more junior analysts)
- Where do existing solutions fail specifically? What complaints do users have?

**For each hypothesis, determine:**
- Does evidence support or contradict this hypothesis?
- Is this a root problem or a symptom of something deeper?
- What did you find that wasn't anticipated by any hypothesis?

**Sources to prioritize:**
- G2, Capterra, TrustRadius reviews of due diligence and data room tools
- Product comparison articles and analyst reports (Gartner, Forrester)
- Competitor websites — feature pages, case studies, pricing
- User complaints and feature requests on review sites
- Industry blog posts comparing tools
- Product Hunt and startup directories for newer entrants

**Citation format:**
- Claim: [finding]
- Relevant hypothesis: [H1, H2, etc. — or "new finding" if not anticipated]
- Source: [org name]
- Date: [date]
- URL: [url]
- Quote: [verbatim excerpt if available]

**Important:** Focus on why solutions fail, not market share or revenue. Document specific gaps and user complaints. Flag uncertainty rather than speculate. If a hypothesis appears to be a symptom rather than a root cause, explain what the deeper cause might be.

**NOT in scope (belongs to Market workspace):** Total addressable market, number of potential users, dollar impact, industry revenue figures, market growth trends.
